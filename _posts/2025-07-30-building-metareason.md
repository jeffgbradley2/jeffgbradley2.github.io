---
layout: post
title: "Building Metareason"
date: 2025-07-30
---

Over the last few years, I've used Large Language Models at work and in my personal life. They amaze me with their ability to understand and produce coherent, useful text. But I'm also regularly let down by them, sometimes in unexpected and subtle ways. Small changes to inputs can produce drastically different outputs. I've spent countless hours evaluating LLMs and building evaluation frameworks, all with the goal of creating AI systems that are consistently trustworthy.

This is no easy task. At the end of the day, it often remains frustratingly qualitative. As I've gone deeper into data science and machine learning, I've started thinking about this problem differently. What if we could go beyond qualitative measures and off-the-shelf evaluation frameworks? What if we could bring classical probability and statistics, math that has stood the test of time, to bear on this problem, combined with modern NLP techniques?

What might that look like? How would it be built?

I think I have a vision for it. MetaReason.

Why "Meta"? Because this is inherently meta, using models to evaluate models. But "meta" also captures the nature of probability and statistics itself. And "Reason"? Well, we're fully in the uncanny valley of machines that can reason. Yes, I know it's "just" simulated reasoning, but so what? If it looks like a duck and quacks like a duck...

I've also become a battle-hardened AI Governance practitioner. My experience taught me that governance matters, but only when it's genuinely beneficial, not just box-checking. And it should be open for all to see.

So MetaReason will be an Open Source, Open Governance company. Something different.

What might that look like? What could it become?

Let's find out.