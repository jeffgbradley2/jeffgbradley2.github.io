---
layout: post
date: 2025-09-30
title: Workslop
---

There is an art to using LLMs effectively for work.

The Harvard Business Review published a recent article titled "[AI-Generated Workslop is Destroying Productivity](https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity)" by Kate Niederhoffer, Gabriella Rosen Kellerman, Angela Lee, Alex Liebscher, Kristina Rapuano and Jeffrey T. Hancock. It's a good read.

## What is Slop

The concept of AI slop isn't new. The term originally seems to have referred to low-quality media, like images and videos. Although the definition is loose, I take "slop" to mean anything generated fully by AI at high volumes with little to no human effort or expertise. As our media landscape becomes flooded with it, this poses potentially significant problems for society.

## Workslop

In the workplace, slop takes on a more immediately problematic role by producing large amounts of low-effort, low-quality content. According to the HBR article, this forces additional work on teams who have to wade through it. They define work slop as "AI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task." That's a solid definition.

## Codeslop

This issue applies directly to code. I've experienced it firsthand using the current generation of coding agents. These tools can produce walls of code that look good superficially but hide issues that require deep analysis to uncover. An engineer can generate lots of code effortlessly, submit a PR without a thorough review, and put the burden on their coworkers to find the problems.

## It's Not All Slop

I'm not a master of practical AI, but there is no denying that how I use it is a major boost to my productivity. However, I have had to learn the hard way when and where to use these tools, and I know that I must fully own and master all content I generate with them.

Hence the recent deletion of 25,000 lines of AI-generated code for a personal project. It wasn't even that the code was wrong; it built and ran. It was that I wasn't a master of it. The code was generated quickly, with low effort, and I had no mastery on my side other than performing code reviews. And code reviews do not produce mastery.

That doesn't mean coding agents aren't useful. At the very least, they are a hell of a rubber ducky, a great pair programmer, and fantastic for looking things up or running shell commands. And they are great at many specific coding tasks. That isn't slop; it's productivity.

Likewise, I have many AI governance tasks before me at all times. These processes require artifacts that follow strict templates, one feeding into the next, and are often just for compliance. This is a great use case for generative AI: creating standardized text from human-generated content. But even then, it isn't a replacement for human judgment and expertise. I still have to guide it, review the output, make corrections, and deeply know and own the content.

## Pilots and Passengers

The HBR article lists ways to counteract the negative effects of work slop. One way is to avoid forcing employees to use AI indiscriminately. I like that, since indiscriminate use of anything is a bad idea. But it seems like most organizations are marketing how they are firing people who can't "upskill" to using AI for all the damn things.

Look, I'm a big believer in using AI and consider myself something of a super user. But we can't use anything indiscriminately and expect good results. We can't offload our responsibility and authority without consequences.

The authors state something else that resonates with me. They say that over the last few years of working with organizations and performing studies, they found two categories of workers: those with high agency and high optimism, and those with low agency and low optimism. The first group they call "pilots" and the second "passengers."

They have found that "pilots" use gen AI far more than passengers, especially outside of work (95% more!). They also found that pilots use gen AI to enhance their creativity far more than passengers and use it far more purposefully to achieve their goals. The "passenger" workers, on the other hand, were found to be much more likely to use AI to avoid work.

## Collaborate More

The authors also pointed out the increased need for quality collaboration, not just between humans, but between humans and AI. This makes a lot of sense. AI can seemingly remove the need to collaborate with others. And if we don't make an effort to collaborate a lot with our AI assistants, if we just accept the first-shot output without discernment or judgment, what we get is more likely to be slop.

I really like this idea of increasing collaboration between humans, as well as between humans and AI. It's important to learn how to integrate AI into our human processes, augmenting ourselves without losing our ability to think critically or building up debt from meaningless work slop. As the authors say, teams should frame AI as a collaborative tool, not a replacement or shortcut. We should all try to be pilots and hold AI-assisted work to the same standards as human work.

It's an art.